services:
  # ============================================
  # Spark + Delta Lake Services
  # ============================================
  
  # PostgreSQL for Hive Metastore backend
  metastore-db:
    image: postgres:15-alpine
    container_name: metastore-db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore
    volumes:
      - metastore_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Hive Metastore Service - connects to PostgreSQL, exposes Thrift API
  hive-metastore:
    build:
      context: .
      dockerfile: hive-metastore.Dockerfile
    image: hive-metastore:4.0.0-postgres
    container_name: hive-metastore
    depends_on:
      metastore-db:
        condition: service_healthy
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: >-
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
        -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://metastore-db:5432/metastore
        -Djavax.jdo.option.ConnectionUserName=hive
        -Djavax.jdo.option.ConnectionPassword=hive
    ports:
      - "9083:9083"
    volumes:
      - ./data/hive-warehouse:/opt/hive/data/warehouse
    healthcheck:
      test: ["CMD", "bash", "-c", "cat < /dev/null > /dev/tcp/localhost/9083"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  spark-jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    image: data-engineering-bootcamp:latest
    container_name: data-engineering-bootcamp
    depends_on:
      hive-metastore:
        condition: service_healthy
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks
      - ./data:/home/jovyan/work/data
      - ./bootcamp:/home/jovyan/work/bootcamp
      - ./main.py:/home/jovyan/work/main.py
      # Mount warehouse at same path as Hive so metastore paths work
      - ./data/hive-warehouse:/opt/hive/data/warehouse
    environment:
      - SPARK_LOCAL_DIRS=/tmp/spark
      - SPARK_WORKER_DIR=/tmp/spark-worker
      - PYTHONPATH=/home/jovyan/work
    shm_size: '2g'
    restart: unless-stopped

  # ============================================
  # Database Explorer (pgAdmin)
  # ============================================
  
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@local.dev
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: "False"
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: "False"
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - ./pgadmin/servers.json:/pgadmin4/servers.json:ro
      - ./pgadmin/pgpass:/pgadmin4/pgpass:ro
    depends_on:
      - metastore-db

volumes:
  metastore_data:
  pgadmin_data:
